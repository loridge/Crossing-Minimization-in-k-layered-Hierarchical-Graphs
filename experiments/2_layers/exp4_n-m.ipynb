{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4 Bipartite n-m graphs experiment\n",
    "\n",
    "A two layer experiment that aims to benchmark barycenter, sifting, and median heuristic algorithms to n-m bipartite graphs generated using NetworkX.\n",
    "In this experiment, singleton nodes are now considered to provide the correct density for smaller graphs since smaller graphs are computationally feasible in our study.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For debugging, most of the functions presented here were copied from the original source files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design \n",
    "\n",
    "n-m bipartite graphs with singleton consideration\n",
    "- n is even (4 6 8 10)\n",
    "- for every n, m is  range[n/2,n],step=1\n",
    "\n",
    "For bipartite graphs, where the singletons are placed does not matter when it comes to solutions. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import networkx as nx \n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from networkx.algorithms import bipartite\n",
    "from itertools import combinations, permutations\n",
    "from typing import Dict, Union, List, Set\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "%load_ext cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph generator/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forced_density_gen_bip_graph(n1, n2, density):\n",
    "    \"\"\"\n",
    "    Generate a bipartite graph with a specified edge density.\n",
    "\n",
    "    Args:\n",
    "        n1 (int): Number of nodes in the first partition (layer 0).\n",
    "        n2 (int): Number of nodes in the second partition (layer 1).\n",
    "        density (float): Desired edge density (0 < density â‰¤ 1), defined as |E| / (|V1| * |V2|).\n",
    "\n",
    "    Returns:\n",
    "        tuple: (nodes, edges, B, top_nodes, bottom_nodes)\n",
    "            - nodes: List of dictionaries with \"id\" and \"depth\".\n",
    "            - edges: List of dictionaries with \"nodes\" as a pair of connected node IDs.\n",
    "            - B: NetworkX bipartite graph.\n",
    "            - top_nodes: Set of nodes in the first partition.\n",
    "            - bottom_nodes: Set of nodes in the second partition.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize bipartite graph\n",
    "    B = nx.Graph()\n",
    "    top_nodes = set(range(1, n1 + 1))\n",
    "    bottom_nodes = set(range(n1 + 1, n1 + n2 + 1))\n",
    "\n",
    "    B.add_nodes_from(top_nodes, bipartite=0)\n",
    "    B.add_nodes_from(bottom_nodes, bipartite=1)\n",
    "\n",
    "    # Compute the exact number of edges required\n",
    "    max_edges = n1 * n2\n",
    "    num_edges = max(1, min(int(math.ceil(density * max_edges)), max_edges))  # Ensure valid range\n",
    "\n",
    "    edges = set()\n",
    "\n",
    "    # Step 1: Shuffle\n",
    "    top_list = list(top_nodes)\n",
    "    bottom_list = list(bottom_nodes)\n",
    "    random.shuffle(top_list)\n",
    "    random.shuffle(bottom_list)\n",
    "\n",
    "    # note that katapat nya yung meron, \n",
    "    # for i in range(max(n1, n2)):\n",
    "    #     u = top_list[i % n1]  # Cycle through top nodes\n",
    "    #     v = bottom_list[i % n2]  # Cycle through bottom nodes\n",
    "    #     edges.add((u, v))\n",
    "    #     B.add_edge(u, v)\n",
    "\n",
    "    # Step 2: Randomly add edges based on density (no forced connections)\n",
    "    while len(edges) < num_edges:\n",
    "        u = random.choice(top_list)\n",
    "        v = random.choice(bottom_list)\n",
    "        if (u, v) not in edges:\n",
    "            edges.add((u, v))\n",
    "            B.add_edge(u, v)\n",
    "\n",
    "    # Convert to required format\n",
    "    nodes = [{\"id\": f\"u{node}\", \"depth\": 0} for node in top_nodes] + \\\n",
    "            [{\"id\": f\"u{node}\", \"depth\": 1} for node in bottom_nodes]\n",
    "\n",
    "    edges = [{\"nodes\": [f\"u{u}\", f\"u{v}\"]} for u, v in edges]\n",
    "    \n",
    "    return nodes, edges, B, top_nodes, bottom_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utilities\n",
    "\n",
    "- parse_edges\n",
    "- cross_count_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_edges(edges, top_nodes, bottom_nodes):\n",
    "    \"\"\"\n",
    "    Parse edges from the given format and map them to integers corresponding to top and bottom nodes.\n",
    "    Args:\n",
    "        edges (list): List of edges in the format [{'nodes': ['u0', 'u6']}, ...].\n",
    "        top_nodes (list): List of top-layer node IDs (e.g., [0, 1, 2]).\n",
    "        bottom_nodes (list): List of bottom-layer node IDs (e.g., [3, 4, 5, 6, 7]).\n",
    "    \n",
    "    Returns:\n",
    "        list: List of tuples representing edges as (top_node, bottom_node).\n",
    "    \"\"\"\n",
    "    parsed_edges = []\n",
    "    for edge in edges:\n",
    "        u, v = edge['nodes']\n",
    "        # Convert 'uX' to integer node IDs\n",
    "        u_id = int(u[1:])  # Remove 'u' and convert to integer\n",
    "        v_id = int(v[1:])\n",
    "        if u_id in top_nodes and v_id in bottom_nodes:\n",
    "            parsed_edges.append((u_id, v_id))\n",
    "        elif v_id in top_nodes and u_id in bottom_nodes:\n",
    "            parsed_edges.append((v_id, u_id))\n",
    "    # print(\"DEBUG: parsed_edges internal\", parsed_edges, \"vs\", edges, \"nodes\",top_nodes, bottom_nodes)\n",
    "    return parsed_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_search_first_smaller(arr, v, lower_bound, upper_bound, index_references, v_index):\n",
    "    \"\"\"\n",
    "    Binary search to find the rightmost index in 'arr' where the value is smaller than 'v'.\n",
    "    The search starts from 'lower_bound' and ends at 'upper_bound' to optimize performance.\n",
    "\n",
    "    Args:\n",
    "        arr (list[str]): The sorted list of neighbor nodes.\n",
    "        v (str): The node to compare against.\n",
    "        lower_bound (int): The starting index for the search.\n",
    "        upper_bound (int): The ending index for the search.\n",
    "        index_references (dict): Dictionary mapping nodes to their fixed_layer indices.\n",
    "        v_index (int): The index of the node 'v' in the fixed layer.\n",
    "\n",
    "    Returns:\n",
    "        int: The index of the last element smaller than 'v', or -1 if none exist.\n",
    "    \"\"\"\n",
    "    left, right = lower_bound, upper_bound\n",
    "    result = -1  # Default to -1 (not found)\n",
    "\n",
    "    while left <= right:  # Fix condition to include rightmost element\n",
    "        mid = (left + right) // 2\n",
    "        # print(f\"DEBUG INSIDE BINSEARCH arr[mid]: {arr[mid]}, left: {left}, right: {right}, mid: {mid}\")\n",
    "\n",
    "        if index_references[arr[mid]] < v_index:\n",
    "            result = mid  # Update result, but keep searching to the right\n",
    "            left = mid + 1\n",
    "        else:\n",
    "            right = mid - 1  # Move left to find a smaller value\n",
    "\n",
    "    return result  # Final rightmost valid index\n",
    "\n",
    "def cross_count_optimized(fixed_layer: list[str], free_layer: list[str], edges: list):\n",
    "    crossing_total = 0\n",
    "    \n",
    "    fixed_layer = [f\"u{node}\" if isinstance(node, int) else node for node in list(fixed_layer) ]\n",
    "    free_layer =  [f\"u{node}\" if isinstance(node, int) else node for node in list(free_layer) ]\n",
    "\n",
    "    fixed_layer_dict = {node: index for index, node in enumerate(fixed_layer)}\n",
    "    free_layer_dict = {node: index for index, node in enumerate(free_layer)}\n",
    "\n",
    "    neighbor_dict = {node: [] for node in free_layer}\n",
    "    easy_free = set(free_layer)\n",
    "    easy_fixed = set(fixed_layer)\n",
    "\n",
    "    for edge_data in edges:\n",
    "        u, v = edge_data[\"nodes\"]\n",
    "        if u in easy_free and v in easy_fixed:\n",
    "            neighbor_dict[u].append(v)\n",
    "        elif v in easy_free and u in easy_fixed:\n",
    "            neighbor_dict[v].append(u)\n",
    "\n",
    "    # Sort neighbors based on their position in fixed_layer\n",
    "    for node in neighbor_dict:\n",
    "        neighbor_dict[node].sort(key=lambda x: fixed_layer_dict[x])\n",
    "\n",
    "    #### CROSSING PROPER ####\n",
    "    for i, u_node in enumerate(free_layer):\n",
    "        u_neighbors = neighbor_dict[u_node]\n",
    "        u_prime_nodes = free_layer[i + 1:]\n",
    "        # print(\"\")\n",
    "        # print(\"u_node \", u_node, \";;;u_prime nodes > u_node: \",u_prime_nodes)\n",
    "        for u_prime in u_prime_nodes:\n",
    "          u_prime_neighbors = neighbor_dict[u_prime]\n",
    "          lb = 0   # 0 indexed as opposed to pseudocode\n",
    "          ub = len(u_prime_neighbors) - 1  # 0 indexed as opposed to pseudocode\n",
    "          # print(f\"DEBUG u-prime-neighbors: {u_prime_neighbors} of u-prime {u_prime}\")\n",
    "          for v in u_neighbors:\n",
    "              result = binary_search_first_smaller(u_prime_neighbors, v, lb, ub, fixed_layer_dict, fixed_layer_dict[v]) ##, edit it must be based on indices not the values of the elements themselves\n",
    "              if result != -1:\n",
    "                crossing_total += result + 1\n",
    "\n",
    "    return crossing_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[comment]: <> (Most of the code are copy-pasted from their original files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
